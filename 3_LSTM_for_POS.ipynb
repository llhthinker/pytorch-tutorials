{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM/Bi-LSTM for Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F \n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dict(training_data):\n",
    "    \n",
    "    word2index = {}\n",
    "    tag2index = {}\n",
    "    for sentence,tags in training_data:\n",
    "        for word in sentence:\n",
    "            if word not in word2index:\n",
    "                word2index[word] = len(word2index)\n",
    "        for tag in tags:\n",
    "            if tag not in tag2index:\n",
    "                tag2index[tag] = len(tag2index)\n",
    "    \n",
    "    return word2index, tag2index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data download:\n",
    "https://github.com/llhthinker/nlptutorial-exercise/blob/master/data/wiki-en-train.norm_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = './data/wiki-en-train.norm_pos'\n",
    "data = load_data(training_file)\n",
    "word2index, tag2index = build_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Natural', 'language', 'processing', '-LRB-', 'NLP', '-RRB-', 'is', 'a', 'field', 'of', 'computer', 'science', ',', 'artificial', 'intelligence', '-LRB-', 'also', 'called', 'machine', 'learning', '-RRB-', ',', 'and', 'linguistics', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '-LRB-', 'natural', '-RRB-', 'languages', '.'], ['JJ', 'NN', 'NN', '-LRB-', 'NN', '-RRB-', 'VBZ', 'DT', 'NN', 'IN', 'NN', 'NN', ',', 'JJ', 'NN', '-LRB-', 'RB', 'VBN', 'NN', 'NN', '-RRB-', ',', 'CC', 'NNS', 'VBN', 'IN', 'DT', 'NNS', 'IN', 'NNS', 'CC', 'JJ', '-LRB-', 'JJ', '-RRB-', 'NNS', '.'])\n",
      "1301\n"
     ]
    }
   ],
   "source": [
    "print(data[0])\n",
    "data_length = len(data)\n",
    "print(data_length)\n",
    "split = int(data_length * 0.7)\n",
    "training_data = data[:split]\n",
    "valid_data = data[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "Ref: http://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html#lstm-s-in-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_seq(seq, seq2index):\n",
    "    indexs = [seq2index[w] for w in seq]\n",
    "    tensor = torch.LongTensor(indexs)\n",
    "    return Variable(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self):\n",
    "        self.vocab_size = len(word2index)\n",
    "        self.tagset_size = len(tag2index)\n",
    "        self.embedding_dim = 16\n",
    "        self.hidden_dim = 16\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(config.vocab_size, config.embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=config.embedding_dim, hidden_size=config.hidden_dim)\n",
    "        \n",
    "        self.hidden2tag = nn.Linear(in_features=config.hidden_dim, out_features=config.tagset_size)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (Variable(torch.zeros(1, 1, config.hidden_dim)),\n",
    "                Variable(torch.zeros(1, 1, config.hidden_dim)))\n",
    "    \n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        embed = self.embedding(sentence)\n",
    "        # lstm input (seq_len, batch, input_size)\n",
    "        embed = embed.view(len(sentence), 1, -1)\n",
    "        lstm_out = self.lstm(embed)[0]\n",
    "#         print(lstm_out.size())\n",
    "        # output (seq_len, batch, hidden_size * num_directions)\n",
    "        # -> (seq_len, hidden_size * num_directions)\n",
    "        lstm_out_reshape = lstm_out.view(len(sentence), -1)\n",
    "#         print(lstm_out_reshape.size())\n",
    "        tag_space = self.hidden2tag(lstm_out_reshape)\n",
    "        tag_scores = F.log_softmax(tag_space)\n",
    "        \n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_eval(model, valid_data):\n",
    "    acc = 0.0\n",
    "    for sentence, tags in valid_data:\n",
    "        sentence_in = prepare_seq(sentence, word2index)\n",
    "        targets = prepare_seq(tags, tag2index)\n",
    "        tag_scores = model(sentence_in)\n",
    "        _, predicted = torch.max(tag_scores.data, 1)\n",
    "        predicted = predicted.view(len(targets)).numpy()\n",
    "        targets = targets.data.numpy()\n",
    "        correct_num = np.sum((predicted == targets))\n",
    "        acc += correct_num / len(sentence)\n",
    "        \n",
    "    print(\"Valid set accuracy:\", acc / len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.324\n",
      "[1,   400] loss: 0.278\n",
      "[1,   600] loss: 0.255\n",
      "[1,   800] loss: 0.240\n",
      "Valid set accuracy: 0.402996500242\n",
      "[2,   200] loss: 0.210\n",
      "[2,   400] loss: 0.202\n",
      "[2,   600] loss: 0.193\n",
      "[2,   800] loss: 0.192\n",
      "Valid set accuracy: 0.515497941108\n",
      "[3,   200] loss: 0.172\n",
      "[3,   400] loss: 0.170\n",
      "[3,   600] loss: 0.167\n",
      "[3,   800] loss: 0.171\n",
      "Valid set accuracy: 0.572909377034\n",
      "[4,   200] loss: 0.154\n",
      "[4,   400] loss: 0.153\n",
      "[4,   600] loss: 0.152\n",
      "[4,   800] loss: 0.158\n",
      "Valid set accuracy: 0.598427265634\n",
      "[5,   200] loss: 0.142\n",
      "[5,   400] loss: 0.142\n",
      "[5,   600] loss: 0.141\n",
      "[5,   800] loss: 0.149\n",
      "Valid set accuracy: 0.617734514808\n",
      "[6,   200] loss: 0.133\n",
      "[6,   400] loss: 0.133\n",
      "[6,   600] loss: 0.132\n",
      "[6,   800] loss: 0.142\n",
      "Valid set accuracy: 0.635239141785\n",
      "[7,   200] loss: 0.126\n",
      "[7,   400] loss: 0.126\n",
      "[7,   600] loss: 0.125\n",
      "[7,   800] loss: 0.136\n",
      "Valid set accuracy: 0.648055034768\n",
      "[8,   200] loss: 0.119\n",
      "[8,   400] loss: 0.119\n",
      "[8,   600] loss: 0.118\n",
      "[8,   800] loss: 0.130\n",
      "Valid set accuracy: 0.658687795378\n",
      "[9,   200] loss: 0.113\n",
      "[9,   400] loss: 0.113\n",
      "[9,   600] loss: 0.112\n",
      "[9,   800] loss: 0.125\n",
      "Valid set accuracy: 0.665739946919\n",
      "[10,   200] loss: 0.109\n",
      "[10,   400] loss: 0.108\n",
      "[10,   600] loss: 0.107\n",
      "[10,   800] loss: 0.121\n",
      "Valid set accuracy: 0.673159377351\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(config)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    count = 0\n",
    "    running_loss = 0.0\n",
    "    for sentence, tags in training_data:\n",
    "        \n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Also, we need to clear out the hidden state of the LSTM,\n",
    "        # detaching it from its history on the last instance.\n",
    "        model.hidden = model.init_hidden()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Variables of word indices.\n",
    "        sentence_in = prepare_seq(sentence, word2index)\n",
    "        targets = prepare_seq(tags, tag2index)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if count % 200 == 199:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, count + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "        count += 1\n",
    "\n",
    "    do_eval(model, valid_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BiLSTMTagger(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BiLSTMTagger, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(config.vocab_size, config.embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=config.embedding_dim, \n",
    "                            hidden_size=config.hidden_dim, \n",
    "                            num_layers= 2,\n",
    "                            bidirectional=True)\n",
    "        \n",
    "        self.hidden2tag = nn.Linear(in_features=config.hidden_dim*2, out_features=config.tagset_size)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (Variable(torch.zeros(1, 1, config.hidden_dim)),\n",
    "                Variable(torch.zeros(1, 1, config.hidden_dim)))\n",
    "    \n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        embed = self.embedding(sentence)\n",
    "        # lstm input (seq_len, batch, input_size)\n",
    "        embed = embed.view(len(sentence), 1, -1)\n",
    "        lstm_out = self.lstm(embed)[0]\n",
    "#         print(lstm_out.size())\n",
    "        # output (seq_len, batch, hidden_size * num_directions)\n",
    "        # -> (seq_len, hidden_size * num_directions)\n",
    "        lstm_out_reshape = lstm_out.view(len(sentence), -1)\n",
    "#         print(lstm_out_reshape.size())\n",
    "        tag_space = self.hidden2tag(lstm_out_reshape)\n",
    "        tag_scores = F.log_softmax(tag_space)\n",
    "        \n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.320\n",
      "[1,   400] loss: 0.294\n",
      "[1,   600] loss: 0.284\n",
      "[1,   800] loss: 0.279\n",
      "Valid set accuracy: 0.239784096097\n",
      "[2,   200] loss: 0.267\n",
      "[2,   400] loss: 0.260\n",
      "[2,   600] loss: 0.251\n",
      "[2,   800] loss: 0.242\n",
      "Valid set accuracy: 0.394927813154\n",
      "[3,   200] loss: 0.215\n",
      "[3,   400] loss: 0.205\n",
      "[3,   600] loss: 0.195\n",
      "[3,   800] loss: 0.192\n",
      "Valid set accuracy: 0.508007925312\n",
      "[4,   200] loss: 0.173\n",
      "[4,   400] loss: 0.168\n",
      "[4,   600] loss: 0.161\n",
      "[4,   800] loss: 0.167\n",
      "Valid set accuracy: 0.554756792656\n",
      "[5,   200] loss: 0.150\n",
      "[5,   400] loss: 0.146\n",
      "[5,   600] loss: 0.140\n",
      "[5,   800] loss: 0.149\n",
      "Valid set accuracy: 0.607302061207\n",
      "[6,   200] loss: 0.133\n",
      "[6,   400] loss: 0.130\n",
      "[6,   600] loss: 0.125\n",
      "[6,   800] loss: 0.136\n",
      "Valid set accuracy: 0.628884194833\n",
      "[7,   200] loss: 0.120\n",
      "[7,   400] loss: 0.117\n",
      "[7,   600] loss: 0.114\n",
      "[7,   800] loss: 0.126\n",
      "Valid set accuracy: 0.647488870077\n",
      "[8,   200] loss: 0.109\n",
      "[8,   400] loss: 0.107\n",
      "[8,   600] loss: 0.104\n",
      "[8,   800] loss: 0.117\n",
      "Valid set accuracy: 0.66449194369\n",
      "[9,   200] loss: 0.101\n",
      "[9,   400] loss: 0.098\n",
      "[9,   600] loss: 0.095\n",
      "[9,   800] loss: 0.110\n",
      "Valid set accuracy: 0.679149682571\n",
      "[10,   200] loss: 0.093\n",
      "[10,   400] loss: 0.090\n",
      "[10,   600] loss: 0.088\n",
      "[10,   800] loss: 0.103\n",
      "Valid set accuracy: 0.692018188963\n"
     ]
    }
   ],
   "source": [
    "model = BiLSTMTagger(config)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    count = 0\n",
    "    running_loss = 0.0\n",
    "    for sentence, tags in training_data:\n",
    "        \n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Also, we need to clear out the hidden state of the LSTM,\n",
    "        # detaching it from its history on the last instance.\n",
    "        model.hidden = model.init_hidden()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Variables of word indices.\n",
    "        sentence_in = prepare_seq(sentence, word2index)\n",
    "        targets = prepare_seq(tags, tag2index)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if count % 200 == 199:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, count + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "        count += 1\n",
    "\n",
    "    do_eval(model, valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmenting the LSTM part-of-speech tagger with character-level features\n",
    "To do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
